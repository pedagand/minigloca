\documentclass[a4paper, 11pt]{article}

\usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathpartir}
\usepackage{tikz}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{color}
\usepackage{mathtools}
\usepackage{caption}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\floatname{algorithm}{Algorithme}

\lstset{frame=tb,
	language=caml,
	columns=[c]fixed,
	basicstyle=\small\ttfamily,
	keywordstyle=\bfseries,
	upquote=true,
	commentstyle=,
	breaklines=true,
	showstringspaces=false,
	stringstyle=\color{green}
}

\title{Minigloca}
\author{Vladislas de Haldat}

\begin{document}

\include{doc-macros.tex}

\maketitle
\newpage
\tableofcontents
\newpage

\section{Un langage impératif simple}
Pour commencer, définissons une syntaxe abstraite minimale que nous utiliserons tout le long de cette étude.
Cette syntaxe se composera de trois blocs fondamentaux que sont les expressions arithmétiques, les expressions
booléennes ainsi que les déclarations. Nous ne considèrerons pas pour le moment la définition de routines au sein de cette syntaxe.

\subsection{Expressions arithmétiques}
Les expressions arithmétiques sont définies sur l'ensemble des entiers relatifs. On se donne les opérateurs
de l'addition, de la soustraction ainsi que de la multiplication. À ces opérateurs l'on pourra appliquer des
entiers ainsi que des identifiants de variables.

% \begin{dtype}{Int}
%   \inlinekind{n}\with{n\in\mathbb{Z}}
% \end{dtype}
% \begin{dtype}{Id}
%   \inlinekind{x}
%   \kind{y}
%   \kind{z}
%   \kind{\ldots}
% \end{dtype}
% \begin{dtype}{Exp_a}
%   \inlinekind{Int}
%   \kind{Id}
%   \kind{op_A (a_1, a_2)}
%   \with{op_A \in\{+, -, \times\}}
% \end{dtype}

\begin{align*}
  Int   & ::= n                               & n \in \mathbb{Z}          \\
  Id    & ::= x	  							  & x \in \mathbb{V}          \\
  Exp_a & ::= Int \mid Id \mid op_A(a_1, a_2) & op_A \in \{+, -, \times\}
\end{align*}
\captionof{figure}{Expression arithmétique}
$\mathbb{V}$ décrira désormais l'ensemble des identifiants de variables affectées dans nos programmes. 
\subsection{Expressions booléennes}
Les expressions booléennes nous permettent d'introduire la comparaison entre deux expressions arithmétiques,
ainsi que les opérateurs booléens sur les expressions booléennes.

\begin{dtype}{Exp_b}
  \inlinekind{\textbf{true}}
  \kind{\textbf{false}}\\
  \akind{op_R (a_1, a_2)}\with{op_R\in\{<, =\}}
  \akind{op_B (b_1, b_2)}\with{op_B\in\{\wedge, \vee\}}
  \akind{\neg{b}}
\end{dtype}
\captionof{figure}{Expression booléenne}

\subsection{Déclarations}
Les déclarations nous permettent de donner forme à notre langage en définissant la séquence de deux instructions ainsi
que les gardes booléennes, sur une condition ou une boucle. On pose la déclaration de la manière suivante,

\begin{dtype}{Stm}
  \inlinekind{\sassign{Id}{Exp_a}}\\
  \akind{\sseq{s_1}{s_2}}\\
  \akind{\sskip}\\
  \akind{\sifthenelse{b}{s_1}{s_2}}\\
  \akind{\swhiledo{b}{s}}
\end{dtype}
Dans le reste de cette étude, on parlera également de déclaration en désignant un programme étant donné que les analyses statiques
n'ont pas besoin d'évaluer la déclaration pour se construire. On notera aussi que la routine peut, pour le moment, être
simplement vue comme la déclaration d'une boucle. Cela sera utile lors des travaux sur la réduction du code mort.

\subsection{Exemple}
Voici un premier exemple sur ce langage
\begin{lstlisting}[tabsize=2]
a := 1;
b := 20;

if a = 3 then
	c := 4
else
	c := 6
endif;

while b < 100 do
	b := b + 1
done
\end{lstlisting}
L'implémentation de tout ce qui est spécifié dans ce document, est écrite en OCaml et est disponible sur le dépôt Git.

\subsection{Arbre de syntaxe abstraite}
De manière à construire nos programmes à partir de ce qui a été précédemment énoncé, il est nécessaire d'introduire 
l'arbre de syntaxe abstraite. Ce modèle de représentation permet de parcourir la déclaration et d'en extraire n'importe
quelle fonctions (dans notre cas les différents opérateurs arithmétiques, booléens, ou d'affectation). 
Cela nous servira particulièrement lors des différentes analyses qui seront effectuées, et notamment l'analyse par flot de contrôle. 
Cette dernière ne requièrant pas la connaissance de l'ordre d'exécution de la déclaration, les AST sont tout-à-fait adaptés.
Voici un exemple d'AST sur notre langage.

\begin{center}\input{ast.fig}\end{center}
\captionof{figure}{Arbre de syntaxe abstraite}

\section{Interpréteur et sémantique}
Dans cette section, on s'atèle à décrire l'interpréteur ainsi que la sémantique sur notre petit langage impératif. Rappelons que
$\mathbb{V}$ est l'ensemble des variables affectées dans un programme.
Dans ce cadre là, on définit l'état d'un programme (sur la pile) par une application entre les identifiants de variables et leurs valeurs, 
dans notre cas, des entiers relatifs,
\[\sigma : \mathbb{V} \longrightarrow \mathbb{Z}\]
On introduit aussi la bijection $\mu_B$,
\[\mu_B : \mathcal{B} \longrightarrow \mathbb{B}\]
où $\mathcal{B} = \{\textbf{true}$, \textbf{false}\} les valeurs booléennes de notre langage et $\mathbb{B} = \{\top, \bot\}$ 
l'ensemble des valeurs booléennes natives à OCaml. Pour la suite, on considèrera l'ensemble des états $\mathcal{S} = \mathbb{Z}^\mathbb{V}$.
Ces derniers décriront l'évolution de l'exécution du programme et nous permettront de formaliser un interpréteur.

\subsection{Interpréteur}
Pour le moment, il n'est pas nécessaire d'implémenter un compilateur pour notre langage, un interpréteur suffira.
Celui-ci servira notamment à valider les tests unitaires lorsque les premières analyses statiques seront appliquées
à nos programmes.
Sur les expressions arithmétiques, définies dans le section précédente, on pose l'application suivante,
\begin{align*}
	\intrfun{Exp_a}{A}:\mathcal{S}&\longrightarrow\mathbb{Z}\\
	\intrfun{n}{A}:\sigma&\longmapsto n\\
	\intrfun{x}{A}:\sigma&\longmapsto\sigma(x)\\
	\intrfun{op_A(a_1, a_2)}{A}:\sigma&\longmapsto\hat{op}_A(\intr{a_1}{A}{\sigma}\text{, }\intr{a_2}{A}{\sigma})\\
\end{align*}
De la même manière, on définit l'application qui suit sur les expressions booléennes,
\begin{align*}
	\intrfun{Exp_b}{B}:\mathcal{S}&\longrightarrow\mathbb{B}\\	
	\intrfun{\textbf{true}}{B}:\sigma&\longmapsto\top\\
	\intrfun{\textbf{false}}{B}:\sigma&\longmapsto\bot\\
	\intrfun{op_R(a_1, a_2)}{B}:\sigma &\longmapsto \hat{op}_R(\intr{a_1}{A}{\sigma}\text{, }\intr{a_2}{A}{\sigma})\\
	\intrfun{op_B(b_1, b_2)}{B}:\sigma&\longmapsto \hat{op}_B(\intr{b_1}{B}{\sigma}\text{, }\intr{b_2}{B}{\sigma})\\
	\intrfun{\neg b}{B}:\sigma&\longmapsto\hat{\neg}\intr{b}{B}{\sigma}
\end{align*}
Les opérateurs de la forme $\hat{op}$ représentent les opérateurs natifs à OCaml.

\subsection{Sémantique}
Maintenant que nous avons correctement défini l'interpréteur, il est possible 
de construire la sémantique du langage. Cela permet également de développer 
un ensemble de règles logiques. La syntaxe de la déclaration des règles,
prenant en compte nos état et déclaration, sera donc de la forme suivante,

\[s, \Sigma \longrightarrow s', \Sigma'\]
\\
où $s$ est la première déclaration, $s'$ celle qui suit après son exécution, 
$\Sigma$ l'état initial et $\Sigma'$  l'état successeur. Commençons 
par la déclaration vide,

\srule{ }{\semanticd{\sskip}{\sigma}{\emptyset}{\sigma}}

Poursuivons avec la déclaration de l'affectation,
\srule{ }{\semanticd{\sassign{x}{a}}{\sigma}{\emptyset}{\sigma'[x\longmapsto\intr{a}{A}{\sigma}]}}
Ici, le nouvel état $\sigma'$ lie l'identifiant de la variable assignée, à la 
valeur de l'expression arithmétique $\intrfun{a}{A}$. Poursuivons avec la règle 
de la séquence entre deux déclarations, d'une part si la première termine,
\srule{\semanticd{s_1}{\sigma}{\emptyset}{\sigma'}}
{\semanticd{\sseq{s_1}{s_2}}{\sigma}{s_2}{\sigma'}}
D'autre part, si la première ne termine pas,
\srule{\semanticd{s_1}{\sigma}{s_1'}{\sigma'}}
{\semanticd{\sseq{s_1}{s_2}}{\sigma}{\sseq{s_1'}{s_2}}{\sigma'}}
La condition peut se formaliser de la sorte dans le cas où la garde est vérifiée,
\srule{\intr{b}{B}{\sigma}}
{\semanticd{\sifthenelse{b}{s_1}{s_2}}{\sigma}{s_1}{\sigma}}
Dans le cas où elle ne l'est pas,
\srule{\neg\intr{b}{B}{\sigma}}
{\semanticd{\sifthenelse{b}{s_1}{s_2}}{\sigma}{s_2}{\sigma}}
On peut déclarer la règle qui suit pour la déclaration while,
\srule{\intr{b}{B}{\sigma}}
{\semanticd{\swhiledo{b}{s}}{\sigma}{\sseq{s}{\swhiledo{b}{s}}}{\sigma}}
\captionof{figure}{Sémantique}

\section{Prérequis à l'analyse}
De manière à pouvoir travailler avec les analyses de flot de données et de flot de contrôle, 
il est nécessaire d'approfondir les principes de bloc et d'étiquettage. Ceux-ci nous fourniront
une bonne représentation de nos programmes, sur laquelle les analyses devront reposer.

\subsection{Blocs}
De manière à faciliter l'analyse sur une déclaration, il est utile de partitionner et de factoriser notre représentation du code. 
Les blocs peuvent être perçus comme un concentré des déclarations atomiques dans un programme. Par exemple, les conditions ainsi
que les boucles reposent toutes deux sur une garde booléenne, on peut donc les factoriser. 
Étant donné l'aspect rudimentaire de notre langage, on peut simplement définir le bloc de la sorte,

\begin{dtype}{Block}
	\inlinekind{\sassign{Id}{Exp_a}}\\
	\akind{Exp_b}\\
	\akind{\sskip}
\end{dtype}

On remarquera que le bloc est défini de manière atomique. Cependant il est tout-à-fait possible de considérer des séquences
d'instructions comme un bloc à part entière, ce qui pourra dans certains cas largement simplifier la représentation du flot
de contrôle.

\subsection{Étiquettage}
De manière à correctement travailler avec ces blocs, il faut avoir une information sur leur position relative, par rapport
aux autres blocs. Il est donc nécessaire de les coupler chacun à un identifiant unique. 
On définit $\mathbb{L}\subseteq\mathbb{N}$ l'ensemble fini des étiquettes d'une déclaration. Introduisons l'application suivante,
\[
	\lambda: Block \longrightarrow \mathbb{L}
\]
\newline
qui prend un bloc et retourne une étiquette unique par rapport au reste des blocs sur une déclaration.
\newline
\newline
\begin{definition}
	Soient $s \in Stm$ et $(l_n)_{n\in\mathbb{N}}$ une suite d'étiquettes construite par $\lambda$ sur $s$.
	On dit que $\lambda$ est bien formée si et seulement si $\forall i \in \mathbb{N}, \forall j \in \mathbb{N}$ 
	tel que $i \neq j$ alors $l_i \neq l_j$.
\end{definition}
\newline
À terme, on voudra représenter le programme par un graphe (le graphe de flot de contrôle) dont chaque noeud représentera un bloc. 
Étant donné une déclaration $s$, on a pour  $b$ un bloc de $s$ que $\delta_-(b) = 1$ le degré entrant et $\delta_+(b) \ge 1$ 
le degré sortant du noeud correspondant dans le graphe de flot de contrôle.
\\
\begin{notation}
	Pour des raisons de commodité, si $s \in Stm$ et $l = \lambda(s)$ alors on notera $s^l \in Stm$ la déclaration munie d'une étiquette.
	Si la déclaration est une condition ou une boucle, l'étiquette sera rattachée à la garde de ces dernières.
\end{notation}
\\
On peut maintenant définir l'application $init$, qui retournera la première étiquette rencontrée dans une déclaration,

\begin{align*}
	init : Stm &\longrightarrow \mathbb{L}\\
	(\sassign{x}{a})^l &\longmapsto l\\
	\sseq{s_1}{s_2} &\longmapsto init(s_1)\\
	{\sskip}^l &\longmapsto l\\
	\sifthenelse{b^l}{s_1}{s_2} &\longmapsto l\\
	\swhiledo{b^l}{s} &\longmapsto l
\end{align*}
Comme expliqué précédemment, il est aussi nécessaire de déclarer une fonction $final$ qui retournera l'ensemble des étiquettes finales 
à la fin d'un bloc.

\begin{align*}
	final : Stm &\longrightarrow \mathcal{P}(\mathbb{L})\\
	(\sassign{x}{a})^l &\longmapsto \{l\}\\
	\sseq{s_1}{s_2} &\longmapsto final(s_2)\\
	\sskip^l &\longmapsto \{l\}\\
	\sifthenelse{b^l}{s_1}{s_2} &\longmapsto final(s_1) \cup final(s_2)\\
	\swhiledo{b^l}{s} &\longmapsto \{l\}
\end{align*}

\subsection{Flots}
\begin{definition}
	Un graphe de flot de contrôle (CFG) est un graphe orienté dont les noeuds représentent les blocs et les arcs un
	flot de contrôle (de même orientation que l'exécution du programme). Dans notre cas, le graphe de flot de
	contrôle aura un seul noeud d'entrée et un seul noeud de sortie.
\end{definition}
\\
En voici quelques exemples,
\begin{center}\input{cfg.fig}\end{center}
\captionof{figure}{Graphe de flot de contrôle}

De manière à correctement identifier chaque bloc lors d'une analyse statique, il nous faut les lier à une étiquette
unique. Pour ce faire, 
on pose l'application $blocks$ définie par,
\begin{align*}
	blocks : Stm &\longrightarrow \mathcal{P}(\mathbb{L} \times Block)\\
	(\sassign{x}{a})^l&\longmapsto\{(l, x := a)\}\\
	\sseq{s_1}{s_2} &\longmapsto blocks(s_1) \cup blocks(s_2)\\
	\sskip^l &\longmapsto \{(l, \textit{Skip})\}\\
	\sifthenelse{b^l}{s_1}{s_2} &\longmapsto \{(l, b)\}\cup blocks(s_1)\cup blocks(s_2)\\
	\swhiledo{b^l}{s} &\longmapsto \{(l, b)\}\cup blocks(s)
\end{align*}
À partir de là, il est possible de formaliser les graphes orientés de flot. Comme déjà expliqué, les blocs en représentent les noeuds, 
et le passage vers le bloc suivant est formulé par un arc.

Nous avons désormais toutes les structures nécéssaires à la construction de notre graphe de flot. Pour le moment, il s'agira de 
le construire naïvement, l'on reviendra plus tard sur les optimisations possibles. Ainsi, une manière simple de représenter ce 
graphe est de considérer l'ensemble des couples d'étiquettes qui indiqueront un arc d'un bloc à un autre. 
Considérons donc l'application suivante, 

\begin{align*}
	flow : Stm &\longrightarrow \mathcal{P}(\mathbb{L}^2) \\
	\sassign{x}{a} &\longmapsto \emptyset \\
	\sskip &\longmapsto \emptyset \\
	\sseq{s_1}{s_2} &\longmapsto flow(s_1) \cup flow(s_2) \cup [final(s_1)\times\{init(s_2)\}] \\
	\sifthenelse{b^l}{s_1}{s_2} &\longmapsto flow(s_1)\cup flow(s_2)\cup\{(l, init(s_1)),(l, init(s_2))\} \\
	\swhiledo{b^l}{s} &\longmapsto flow(s)\cup\{(l,init(s))\}\cup[final(s)\times\{l\}]
\end{align*}
On introduira aussi un accès à l'ensemble des successeurs d'un bloc par l'application,
\begin{align*}
	succ : \mathbb{L} &\longrightarrow \mathcal{P}(\mathbb{L})\\
	l &\longmapsto \{l' \in \mathbb{L} \mid (l, l') \in \mathcal{G}_V\},
\end{align*}
où $\mathcal{G}_V$ est l'ensemble des arcs du graphe de flot de contrôle du programme. Réciproquement, on 
utilisera $pred$ qui donnera cette fois-ci accès aux prédecesseurs d'un bloc.

\section{Analyse de vivacité}
La première analyse statique sur laquelle nous travaillons est l'analyse de vivacité des variables dans nos programmes. 
Il s'agira donc de déterminer pour chaque bloc, l'ensemble de variables encore vivantes, c'est-à-dire
encore utilisées une fois le présent bloc passé. Pour cela, il faut au préalable déclarer quelques ensembles 
nécessaires à cette analyse.

\subsection{Description ensembliste d'un programme}
On se donne $(\mathcal{P}(\mathbb{V}), \subseteq)$ l'ensemble partiellement ordonné des parties de $\mathbb{V}$, 
le treillis sur lequel on travaillera désormais.
\\
Pour $l \in \mathbb{L}$ l'étiquette d'un bloc, on définit les ensembles qui suivent,
\[\sgen{l} \subseteq \mathcal{P}(\mathbb{V})\]
l'ensemble des variables appelées dans le bloc en question et,
\[\skill{l} \subseteq \mathcal{P}(\mathbb{V})\]
l'ensemble des variables nouvellement affectées, donc considérées pour lors comme mortes. Enfin on se donnera,
\[vars_a : Exp_a \longrightarrow \mathcal{P}(\mathbb{V})\]
l'ensemble des identifiants de variables présentes dans une expression arithmétique et,
\[vars_b : Exp_b \longrightarrow \mathcal{P}(\mathbb{V})\]
l'ensemble des identifiants de variables présentes dans une expression booléenne.
\\
Définissons maintenant la construction de ces deux ensembles à partir d'un bloc comme,
\begin{align*}
	gen : Block &\longrightarrow \mathcal{P}(\mathbb{V})\\
	\sassign{x}{a} &\longmapsto vars_a(a)\\
	\sskip &\longmapsto \emptyset\\
	b &\longmapsto vars_b(b)
\end{align*}
génère l'ensemble $\sgen{l}$ et,
\begin{align*}
	kill : Block &\longrightarrow \mathcal{P}(\mathbb{V})\\
	\sassign{x}{a} &\longmapsto \{x\}\\
	\sskip &\longmapsto \emptyset\\
	b &\longmapsto \emptyset
\end{align*}
génère l'ensemble $\skill{l}$.
\\
\\
Notre langage étant un langage impératif, il est par conséquent naturel d'effectuer cette analyse de bas en haut dans le parcours des déclarations,
de manière à déterminer cette vivacité. Pour pouvoir donner forme à cette analyse, on déclare deux ensembles de variables vivantes à l'entrée, et à la
sortie d'un bloc. Ils nous permettront par la suite de résoudre un système d'équation par itération et d'y trouver un point fixe. 
On les définira comme tels,

\[
	LIVE_{out}[l] = 
	\begin{dcases*}
		\emptyset &si $succ(l) = \emptyset $\,, \\
		\bigcup\limits_{p\in succ(s)} LIVE_{in}[p] &sinon\,,
	\end{dcases*}
\]
l'ensemble des variables vivantes à la sortie d'un bloc et,

\[
	LIVE_{in}[l] = \sgen{l} \cup (LIVE_{out}[l] - \skill{l}),
\]
l'ensemble des variables vivantes à l'entrée d'un bloc.
\\
\begin{notation}
	Si $Z$ est une solution du système d'équation sur un treillis $(L, \sqsubseteq)$, on notera aussi $Z_l \subseteq L$
	la solution au bloc d'étiquette $l$.
\end{notation}
\\
À ce stade, nous ne pouvons pas encore effectuer l'analyse de vivacité sur nos programmes, il nous manque en
effet un algorithme d'itération qui puisse résoudre le système d'équation qui est un point fixe en chaque bloc.
La finalité étant de trouver le point fixe minimal.

\subsection{Monotonie}
La monotonie des ensembles de flot de données nous permettra de garantir ou non que le point fixe déterminé par un
algorithme est le point fixe minimal. 
Cela sera donc utile pour prouver la terminaison des algorithmes, étant donné que l'ensemble des variables $\mathbb{V}$ d'une déclaration est supposé fini.
\\
\\
\begin{lemma}
	Pour tout $l \in \mathbb{L}$ alors $\livein{l}$ et $\liveout{l}$ sont monotones.
\end{lemma}
\\
\begin{proof}	
Posons les applications,
\begin{align*}
	f : \mathcal{P}(\mathbb{V}) &\longrightarrow \mathcal{P}(\mathbb{V}) \\
	X_l &\longmapsto \sgen{l} \cup (g(X_l) - \skill{l})
\end{align*}
où
\begin{align*}
	g : \mathcal{P}(\mathbb{V}) &\longrightarrow \mathcal{P}(\mathbb{V})\\
	X_l &\longmapsto \bigcup\limits_{p\in succ(l)} f(X_p)
\end{align*}
Soient $K_l, K'_l \in \mathcal{P}(\mathbb{V})$ deux analyses de même étiquette sur deux déclarations différentes au bloc
d'étiquette $l$ sur $s \in Stm$ une déclaration. Elles sont telles que $K_l \subseteq K'_l$. On a alors,
\[
	g(K_l) \subseteq g(K'_l)
\]
comme $g$ ne traite que les blocs successeurs à ce bloc d'étiquette $l$, qui sont donc les mêmes.
Ensuite on a $gen_K[l] \subseteq gen_{K'}[l]$ (par monotonie croissante de l'union) mais aussi $kill_{K'}[l] \subseteq kill_K[l]$ (par monotonie décroissante
de la différence ensembliste) et d'après le précédent
résultat, $g(K_l) \subseteq g(K'_l)$. Donc, par monotonie croissante de l'union on a bien
\[
	f(K_l) \subseteq f(K'_l)	
\]
Ainsi $\livein{l}$ et $\liveout{l}$ sont monotones croissantes.
\end{proof}

\subsection{Point fixe}
Revenons-en à l'existence d'un point fixe, pour pouvoir construire un algorithme itératif. On dispose que 
$(\mathcal{P}(\mathbb{V}), \subseteq)$ est un ensemble muni d'un ordre partiel et est fini.
Ainsi, grâce à la monotonie de nos deux ensembles $\livein{\cdot}$ et $\liveout{\cdot}$, démontrée ci-dessus, il
vient qu'à chaque itération de notre algorithme, l'ensemble produit sera soit identique à l'ensemble précédent,
soit plus gros et la finitude de l'ensemble des variables assure qu'il ne pourra par grossir indéfiniment. 
Il faut cependant aussi avoir la garantie que la solution trouvée soit la plus petite qui puisse exister.
On se sert pour y parvenir du théorème du point fixe de Kleene.
\\
\\
\begin{theorem}
	Soit $(L, \sqsubseteq)$ un ordre partiellement ordonné, avec un plus petit élément  $\perp$ et soit
	une application $f : L \longrightarrow L$ monotone. Alors il existe un point fixe minimal qui est le suprémum de la suite,
	\[\perp \sqsubseteq f(\perp) \sqsubseteq f^2(\perp) \sqsubseteq \cdots \sqsubseteq f^k(\perp) \sqsubseteq \cdots\]
\end{theorem}
\begin{proof}
	[admise]
\end{proof}
Commençons par établir un algorithme de point fixe naïf. Il s'agira simplement de recalculer l'entierté du système
d'équation à chaque itération, jusqu'à trouver le point fixe minimal (par le théorème de Kleene).

\begin{algorithm}[H]
	\caption{Itération du point fixe}
	\begin{algorithmic}
		\State {Soit $s$ la déclaration}
		\State $\mathcal{B} \leftarrow blocks(s)$
		\State {Soit $\mathbb{L}$ l'ensemble des étiquettes de $\mathcal{B}$}
		\For{$l \in \mathbb{L}$}
		\State $live_{in}[l] \leftarrow \emptyset$
		\State $live_{out}[l] \leftarrow \emptyset$
		\EndFor
		\While{$live_{in} \ne live_{in}' \textbf{ ou } live_{out} \ne live_{out}'$}
		\For{$l \in L$}
		\State $live_{out}[l] \leftarrow \bigcup\limits_{p\in succ(l)} live_{in}[p]$
		\State $live_{in}[l] \leftarrow \sgen{l} \cup (live_{out}[l] - \skill{l})$
		\EndFor
		\EndWhile
	\end{algorithmic}
\end{algorithm}
Si $n = \#\mathbb{L}$, alors cet algorithme a une complexité en $O(kn)$, où $k$ est la hauteur du diagramme
de Hasse sur $(\mathcal{P}(\mathbb{V}), \sqsubseteq)$. Cela se montre grâce à la monotonie de $\livein{\cdot}$, 
celle-ci ne faisant que croître vers $\top$.
Concernant l'implémentation, il peut être intéressant de définir $live_{in}$ et $live_{out}$ comme une structure binaire de taille au
moins $m$ bits avec $m = \#\mathbb{V}$.
En outre, une amélioration peut être simplement faite sur l'algorithme décrit ci-dessus en remarquant qu'à chaque 
modification effective de $\liveout{\cdot}$, seuls les blocs prédecesseurs seront susceptibles de s'altérer. Cela
vient du fait que l'analyse se fait de bas en haut. Donc
au lieu d'itérer à nouveau sur l'ensemble des blocs, il suffit d'itérer uniquement sur les blocs, prédecesseurs au dernier
bloc altéré. L'on décrira ce second algorithme plus bas dans la section.
\\
\\
\begin{lemma}
	Étant donné $s \in Stm$ un déclaration, à partir de $\bot$ l'algorithme d'itération du point fixe trouve effectivement
	un point fixe sur $s$ et termine.
\end{lemma}
\\
\begin{proof}
Les correction et terminaison de l'algorithme reposent en partie sur ce qui a été dit en amont de cette section.
On utilise deux fonctions croissantes monotones. Posons $f = live_{in}$ étant donné qu'on peut se restreindre
à l'étude de $\livein{\cdot}$. À chaque itération deux cas s'offrent,
\begin{enumerate}
	\item si on atteint un point fixe pour tout $l \in \mathbb{L}$, on a $f^k(\bot)$ stationnaire
	à partir de la $k$-ème itération. De plus, par monotonie de $f$, c'est le suprémum des $f^n(\bot)$ pour tout $n \in \mathbb{N}$ donc
	l'algorithme a trouvé le point fixe minimal, par le théorème de Kleene.
	\item sinon, le treillis a crû, par croissance monotone de $f$. Étant donné qu'on suppose $\mathbb{V}$ fini, le treillis continuera
	de croître jusqu'à atteindre le premier cas évoqué, ou alors le cas $f^k(\bot) = \top$ pour tout $k \ge N \in \mathbb{N}$.
\end{enumerate}
Ainsi l'algorithme termine et trouve bien le plus petit point fixe.
\end{proof}
\\
Dans cette étude, nous travaillerons avec les deux algorithmes évoqués pour réaliser les tests unitaires. Ci-dessous, un aperçu du fonctionnement
de l'algorithme par worklist et sa correction.

\begin{algorithm}[H]
	\caption{Itération du point fixe (worklist)}
	\begin{algorithmic}
		\State $\mathcal{Q} \leftarrow \mathbb{L}$ une queue des étiquettes
		\For{$l \in \mathbb{L}$}
		\State $live_{in}[l] \leftarrow \emptyset$
		\State $live_{out}[l] \leftarrow \emptyset$
		\EndFor
		\While{$\#\mathcal{Q} > 0$}
		\State $q \leftarrow \mathcal{Q}$.pop
		\State $live_{in}'[q] \leftarrow live_{in}[q]$
		\State $live_{out}[q] \leftarrow \bigcup\limits_{p\in succ(q)} live_{in}[p]$
		\State $live_{in}[q] \leftarrow \sgen{q} \cup (live_{out}[q] - \skill{q})$
		\If {$live_{in}[q] \ne live_{in}'[q]$}
		\State $\mathcal{Q}$.push(pred(q))
		\EndIf
		\EndWhile
	\end{algorithmic}
\end{algorithm}
\noindent
\begin{lemma}
	Étant donné $s \in Stm$ une déclaration, à partir de $\bot$ l'algorithme par worklist trouve effectivement
	un point fixe sur $s$ et termine.
\end{lemma}
\\
\begin{proof}
On remarque qu'à la modification de l'analyse de vivacité $\liveout{\cdot}$,
les blocs successeurs ne seront nullement impactés. En effet seuls les blocs prédecesseurs seront
altérés d'après notre définition ensembliste de la vivacité. L'algorithme est donc une restriction de l'algorithme naïf vu plus
haut. Posons $f = live_{in}$, on a deux cas,
\begin{enumerate}
	\item si pour $l \in \mathbb{L}$ on a trouvé un point fixe, c'est que l'élément $live_{in}[l]$ n'a pas été modifié donc
	l'algorithme n'ajoute pas ses prédecesseurs à la queue. Ainsi, si on a trouvé une solution globale à la $k$-ème itération, 
	alors $Card_k(\mathcal{Q}) > Card_{k+1}(\mathcal{Q}) > \cdots > Card_{k + n}(\mathcal{Q}) = 0$. Cela est du au fait que
	l'algorithme n'ajoute plus rien à la queue mais lui retire un élément à chaque itération. Comme $f$ est monotone, on
	a bien trouvé le point fixe minimal, par le théorème de Kleene.
	\item sinon le treillis a crû et l'algorithme traite, en plus, les prédecesseurs du bloc altéré. Étant donné $\mathbb{V}$ fini,
	on itère jusqu'à atteindre le premier cas, ou bien le cas où $f^k(\bot) = \top$ pour tout $k \ge N \in \mathbb{N}$.
\end{enumerate}
À partir du moment où l'algorithme trouve un point fixe minimal ou bien qu'il atteint $\top$, la queue $\mathcal{Q}$ ne se remplit
plus mais est dépilée à chaque itération. Donc l'algorithme trouve bien le point fixe minimal et termine.
\end{proof}
\subsection{Exemple}
\noindent
Considérons une déclaration simple comme celle-ci,
\begin{lstlisting}[tabsize=2]
	a := 0;
	b := a;
	while a < 100 do
		a := a + 1
	done;
	c := b + a
\end{lstlisting}
On obtient donc l'analyse de vivacité suivante, en appliquant l'un des deux algorithmes explicités ci-dessus,
\\
\begin{center}
	\begin{tabular}{||c|l|r|l||}
	\hline
	Étiq. & Bloc & $\livein{\cdot}$ & $\liveout{\cdot}$ \\
	\hline
	1 & a := 0 & $\emptyset$ & $\{a\}$\\
	2 & b := a & $\{a\}$ & $\{a, b\}$\\
	3 & while a < 100 do & $\{a, b\}$ & $\{a, b\}$\\
	4 & a := a + 1 & $\{a, b\}$ & $\{a, b\}$\\
	- & done & - & -\\
	5 & c := b + a & $\{a, b\}$ & $\emptyset$\\
	\hline
	\end{tabular}
\end{center}
\section{Élimination de code mort}
Cette analyse permet une première optimisation qu'est l'élimination de code mort. Elle consiste, en pré-compilation,
à générer un nouveau code à partir du code initial, dans lequel le code dit mort n'est plus présent.
On définira ici le code mort comme un ensemble de blocs d'une déclaration, qui ne seront jamais utilisés.

\subsection{Réduction naïve}
Cette optimisation peut en premier lieu être abordée de manière naïve. On notera $\mathcal{A}$ l'analyse de flot de donnée.
Considérons $\Delta$ la fonction d'élimination du code mort définie par,
\[\Delta : \mathcal{A} \times Stm \longrightarrow Stm\]
et qui, à partir d'une analyse de flot de donnée et d'une déclaration, produit une nouvelle déclaration. Soit $s \in Stm$, alors
$s' = \Delta(\bot, s)$ est itérée jusqu'à atteindre $s' = s$. À chaque itération,
l'analyse de vivacité de la nouvelle déclaration est à nouveau calculée à partir de $\bot$.

\subsection{Exemple}
\noindent
Considérons le programme suivant,
\begin{lstlisting}[tabsize=2]
	a := 1;
	b := 0;
	c := a + b;
	while b < 100 do
		b := b + 1
	done;
	d := 2 * c
\end{lstlisting}
On a donc l'analyse de vivacité,
\begin{center}
\begin{tabular}{||c|l|r|l||}
\hline
Étiq. & Bloc & $\livein{\cdot}$ & $\liveout{\cdot}$ \\
\hline
1 & a := 1 & $\emptyset$ & $\{a\}$\\
2 & b := 20 & $\{a\}$ & $\{a, b\}$\\
3 & c := a + b & $\{a, b\}$ & $\{b, c\}$\\
4 & while b < 100 do & $\{b, c\}$ & $\{b, c\}$\\
5 & b := b + 1 & $\{b, c\}$ & $\{b, c\}$\\
- & done & - & -\\
6 & d := 2 * c & $\{c\}$ & $\emptyset$\\
\hline
\end{tabular}
\end{center}
On remarque que $\liveout{6} = \emptyset$ donc $d$ est morte après avoir été affectée. L'algorithme applique donc sur ce bloc
une tranformation vers une instruction $Skip$, puis calcule à nouveau l'analyse, à partir de $\bot$. On obtient alors l'analyse
de vivacité,
\begin{center}
	\begin{tabular}{||c|l|r|l||}
	\hline
	Étiq. & Bloc & $\livein{\cdot}$ & $\liveout{\cdot}$ \\
	\hline
	1 & a := 1 & $\emptyset$ & $\{a\}$\\
	2 & b := 20 & $\{a\}$ & $\{a, b\}$\\
	3 & c := a + b & $\{a, b\}$ & $\{b\}$\\
	4 & while b < 100 do & $\{b\}$ & $\{b\}$\\
	5 & b := b + 1 & $\{b\}$ & $\{b\}$\\
	- & done & - & -\\
	6 & () & $\emptyset$ & $\emptyset$\\
	\hline
	\end{tabular}
\end{center}
De la même manière, $\liveout{3} \cap \{c\} = \emptyset$ donc cette variable est considérée comme morte dans la suite de la déclaration.
L'algorithme transforme donc le bloc en question en $Skip$ puis calcule, de la même manière, l'analyse de vivacité.
\begin{center}
	\begin{tabular}{||c|l|r|l||}
	\hline
	Étiq. & Bloc & $\livein{\cdot}$ & $\liveout{\cdot}$ \\
	\hline
	1 & a := 1 & $\emptyset$ & $\emptyset$\\
	2 & b := 20 & $\emptyset$ & $\{b\}$\\
	3 & () & $\{b\}$ & $\{b\}$\\
	4 & while b < 100 do & $\{b\}$ & $\{b\}$\\
	5 & b := b + 1 & $\{b\}$ & $\{b\}$\\
	- & done & - & -\\
	6 & () & $\emptyset$ & $\emptyset$\\
	\hline
	\end{tabular}
\end{center}
Enfin, $\liveout{1} = \emptyset$ donc la variable $a$ est morte dans la suite de la déclaration, le bloc d'étiquette 1 est à son tour
réduit, et l'on atteint un point fixe sur la réduction, c'est-à-dire que l'algorithme ne peut plus réduire quoi que ce soit et renvoie
toujours la même déclaration. Cela termine avec la déclaration réduite,
\begin{lstlisting}[tabsize=2]
	();
	b := 0;
	();
	while b < 100 do
		b := b + 1
	done;
	()
\end{lstlisting}
\subsection{Incrémentalisation de la réduction}
Cette réduction naïve est cependant particulièrement inefficace. En effet, elle doit à chaque itération calculer
l'analyse à partir de $\bot$ et cela peut s'avérer lourd lorsque nos programmes se composent de milliers de blocs.
On introduit donc la réduction de code mort par incrémentalisation, dans laquelle on essaye plutôt de calculer
la nouvelle analyse de vivacité à partir de la précédente, ce qui réduit considérablement le nombre d'opérations.
Pour résumer l'idée, voilà comment nous pourrions définir cette fois notre application de réduction,
\[\Delta : \mathcal{A} \times Stm \longrightarrow \mathcal{A} \times Stm \]
qui se rappelle récursivement, en utilisant la précédente analyse pour réduire la nouvelle déclaration.
\\
\begin{notation}
	Par la suite, si $s \in Stm$ une déclaration, on notera $\reduced{s}{\mathcal{L}}{Skip}$ cette même déclaration, 
	réduite aux blocs d'étiquette dans $\mathcal{L}$.
\end{notation}

Cependant, si on considère $s \in Stm$, $\mu_s$ son point fixe minimal et $s' = \reduced{s}{\mathcal{L}}{Skip}$ cette même déclaration
réduite, alors il n'est pas possible d'utiliser l'analyse de vivacité de $s$ pour poursuivre la réduction, étant donné qu'on ne peut pas garantir que
$\mu_{s} \subseteq \mu_{s'}$ et que, comme démontré plus haut, la recherche de point fixe est croissante monotone uniquement. 
Il s'agit donc de trouver un moyen de suffisament décroître le précédent treillis pour obtenir un pré-point fixe, qu'on pourra alors itérer et obtenir
le point fixe minimal.
Pour ce faire, on peut introduire un ensemble $\filterset$ qui agit comme un filtre de manière à supprimer l'information en trop. 
Pour convenablement filtrer le treillis de $s$, il faut ajouter de l'information à cette dernière. 
En effet, il est nécessaire qu'à chaque bloc $b$, il soit possible de connaître quel bloc sous-jacent
a besoin des variables vivantes en $b$. Le treillis utilisé manque alors d'information et n'est plus adapté, étant donné qu'il n'est pas en mesure
d'indiquer d'où vient la propagation d'une variable vivante. Donc le filtrer ne nous avancerait pas, étant donné qu'on n'obtiendra pas de
pré-point fixe, mais quelque chose de beaucoup plus petit. On essayera donc plutôt d'utiliser le treillis $(\mathcal{P}(\mathbb{L} \times \mathbb{V}), \sqsubseteq)$. 
\\
\\
En ce qui concerne la comparaison de ces paires, elle dépend de la manière avec laquelle l'algorithme de réduction parcourira la déclaration donnée.
En effet, si celui-ci se fait strictement de bas en haut, alors la comparaison peut uniquement se faire sur la variable. Nous préférerons néanmoins
que ce treillis serve quelque soit l'ordre dans lequel l'algorithme effectue la réduction, la comparaison se fera donc sur l'étiquette
et sur la variable. Une fois cela acquis, il est possible d'énoncer le théorème qui suit.
\\
\\
\begin{theorem}
	Soient $s \in Stm$, et $s' = \reduced{s}{\mathcal{L}}{Skip}$ une réduction sur
	l'ensemble d'étiquettes $\mathcal{L}$. Soient $\mu_s$ et $\mu_{s'}$ les point fixes minimaux respectifs
	des deux déclarations.
	Alors $\exists \filterset$ tel que $\forall l \in \mathbb{L}$,
	\[
		\mu_s[l] - \filterset \subseteq \mu_{s'}[l]
	\]
	est un pré-point fixe de $\mu_{s'}[l]$.
\end{theorem}
\\
\\
\begin{proof}
	Soient $s \in Stm$ et $s' := s[\mathcal{L} \longmapsto Skip]$ la déclaration à partir de $s$ dont les blocs d'étiquette 
	dans $\mathcal{L}$ sont réduits. 
	On se place en outre sur le treillis $(\mathcal{P}(\mathbb{L} \times \mathbb{V}), \subseteq)$. 
	Une fois cela donné, on redéfinit ce que sont $vars$, $gen$ et $kill$ de la manière qui suit, 
	\[vars_a : \mathbb{L} \times Exp_a \longrightarrow \mathcal{P}(\mathbb{L} \times \mathbb{V})\]
	retourne désormais l'ensemble des variables d'une expression arithmétique, liées chacunes à l'étiquette du bloc qui les génère et,
	\[vars_b : \mathbb{L} \times Exp_b \longrightarrow \mathcal{P}(\mathbb{L} \times \mathbb{V})\]
	retourne désormais l'ensemble des variables d'une expression booléennes, liées chacunes à l'étiquette du bloc qui les génère.
	\begin{align*}
		gen : \mathbb{L} \times Block &\longrightarrow \mathcal{P}(\mathbb{L} \times \mathbb{V})\\
		(l, \sassign{x}{a}) &\longmapsto vars(l, a)\\
		(l, \sskip) &\longmapsto \emptyset\\
		(l, b) &\longmapsto vars(l, b)
	\end{align*}
	génère maintenant l'ensemble $\sgen{l}$ et,
	\begin{align*}
		kill : Block &\longrightarrow \mathcal{P}(\mathbb{L} \times \mathbb{V})\\
		\sassign{x}{a} &\longmapsto \mathbb{L} \times \{a\}\\
		\sskip &\longmapsto \emptyset\\
		b &\longmapsto \emptyset
	\end{align*}
	génère maintenant l'ensemble $\skill{l}$.
	\\ 
	Par commodité pour la suite, on se donnera les applications,
	\begin{align*}
		g : \mathcal{P}(\mathbb{L} \times \mathbb{V}) &\longrightarrow \mathcal{P}(\mathbb{L} \times \mathbb{V})\\
		X_l &\longmapsto \bigcup\limits_{p\in succ(l)} f(X_p)
	\end{align*}
	monotone croissante, d'après la démonstration sur la monotonie de $\liveout{\cdot}$ ci-dessus où,
	\begin{align*}
		f : \mathcal{P}(\mathbb{L} \times \mathbb{V}) &\longrightarrow \mathcal{P}(\mathbb{L} \times \mathbb{V})\\
		X_l &\longmapsto \sgen{l} \cup (g(X_l) - \skill{l})
	\end{align*}
	également monotone croissante par la démonstration sur la monotonie de $\livein{\cdot}$ ci-dessus.
	On pose $E_s$ et $E_{s'}$ les deux systèmes d'équations respectivement de $s$ et de $s'$,
	\[
	E_s :
	\begin{dcases*}
		\livein{l} = f(\livein{l}) &$\forall l \in \mathbb{L} - \mathcal{L}$\,, \\
		\livein{k} = f(\livein{k}) &$\forall k \in \mathcal{L}$\,,
	\end{dcases*}
	\]
	et
	\[
	E_{s'} :
	\begin{dcases*}
		\livein{l} = f(\livein{l}) &$\forall l \in \mathbb{L} - \mathcal{L}$\,,\\
		\livein{k} = g(\livein{k}) &$\forall k \in \mathcal{L}$\,.
	\end{dcases*}
	\]
	Posons enfin, l'ensemble filtre tel que,
	\[
		\filterset = \{(l, v) \mid l \in \mathcal{L}, v \in \mathbb{V}\}
	\]
	On considère $Z = (Z_l)_{l\in \mathbb{L}}$ le plus petit point fixe de la déclaration $s$ \textit{i.e.} la plus petite solution du système $E_s$.
	Montrons d'abord que $\forall X = (X_l)_{l\in \mathbb{L}}$ solution de $E_{s'}$ alors,
	\[Z_k - \filterset \subseteq X_k, \forall k \in \mathcal{L}\]
	D'après la définition de $gen$ sur ce treillis il vient que $\sgen{k} \subseteq I_{\mathcal{L}}$, donc on a
	\[Z_k - \filterset = g(Z_k) - (\skill{k} - \{(k, v) \mid v \in \mathbb{V}\}) \subseteq g(Z_k) \subseteq g(X_k) = X_k\]
	comme on suppose $Z$ la plus petite solution du système $E_s$.
	Montrons ensuite que $\forall X = (X_l)_{l\in \mathbb{L}}$ solution de $E_{s'}$ on a,
	\[
		Z_l - \filterset \subseteq X_l, \forall l \in \mathbb{L} - \mathcal{L}
	\]
	Dans ce cas, on remarque que 
	\[Z_l - X_l = Z_l \cap \filterset\] 
	mais aussi que, 
	\[X_l - Z_l \subseteq \mathcal{U} = \bigcup\limits_{k\in \mathcal{L}} g(X_k) \cap \skill{k}\]
	et ainsi que,
	\[g(Z_l) - I_{\mathcal{L}} \subseteq g(X_l)\]
	Donc on obtient que,
	\[
		Z_l - \filterset = \sgen{l} \cup (g(X_l) - \mathcal{U} - \skill{l}) \subseteq f(X_l) = X_l
	\]
	Étant donné que $[g(X_l) - \mathcal{U}] \cap \filterset = \emptyset$ il n'est pas nécessaire de retirer à $\skill{l}$ les possibles
	éléments dans $\mathcal{L}$.
	Donc pour tout $X$ solution du système $E_{s'}$ et pour tout $l \in \mathbb{L}$, on a montré que $Z_l - \filterset \subseteq X_l$ .
	La différence ensembliste étant monotone décroissante, on a bien que la différence de $\filterset$ à $Z$
	est un pré-point fixe de $\mu_{s'}$, la plus petite solution de $E_{s'}$.
\end{proof}
\subsection{Exemple}
Illustrons tout ce qui vient d'être dit, avec une déclaration sur laquelle on applique une incrémentalisation, d'abord à l'aide du premier
treillis, puis à l'aide du second. Considérons la déclaration,
\begin{lstlisting}[tabsize=2]
	a := 0;
	b := a;
	while a < 100 do
		a := a + 1;
		c := a + b
	done;
	d := a * b * c
\end{lstlisting}
On trouve donc la première analyse de vivacité, à partir de $\bot$ sur le treillis $(\mathcal{P}(\mathbb{V}), \subseteq)$
\begin{center}
	\begin{tabular}{||c|l|r|l||}
	\hline
	Étiq. & Bloc & $\livein{\cdot}$ & $\liveout{\cdot}$ \\
	\hline
	1 & a := 1 & $\emptyset$ & $\{a\}$\\
	2 & b := a & $\{a\}$ & $\{a, b\}$\\
	3 & while a < 100 do & $\{a, b\}$ & $\{a, b\}$\\
	4 & a := a + 1 & $\{a, b\}$ & $\{a, b\}$\\
	5 & c := a + b & $\{a, b\}$ & $\{a, b, c\}$\\
	- & done & - & -\\
	6 & d := a * b * c & $\{a, b, c\}$ & $\emptyset$\\
	\hline
	\end{tabular}
\end{center}
Supposons désormais, qu'on veuille réduire le bloc d'étiquette 5, et produire la nouvelle analyse de vivacité
à partir de celle décrite ci-dessus. En ce bloc, on a $\sgen{5} = \{a, b\}$ donc il faut propager la perte de vivacité
de ce bloc, vers ses blocs prédecesseurs. Vient le problème de l'origine de la vivacité sur une variable. En effet,
en l'état de ce treillis, il est impossible de savoir, ni qui utilise ces variables dans les blocs successeurs ni qui
maintient la vivacité, pour cause du bloc 5, dans les blocs prédecesseurs. Donc on ne peut pas garantir l'obtention d'un
pré-point fixe sur le code réduit. Essayons désormais le second treillis, 
$(\mathcal{P}(\mathbb{L} \times \mathbb{V}), \subseteq)$. Cette fois-ci, on trouve la première analyse de vivacité, à partir
de $\bot$,
\begin{center}
	\begin{tabular}{||c|l|r|l||}
	\hline
	Étiq. & Bloc & $\livein{\cdot}$ & $\liveout{\cdot}$ \\
	\hline
	1 & a := 1 & $\emptyset$ & $\{a_2, a_3, a_4\}$\\
	2 & b := a & $\{a_2, a_3, a_4\}$ & $\{a_3, a_4, b_5, b_6\}$\\
	3 & while a < 100 do & $\{a_3, a_4, b_5, b_6\}$ & $\{a_4, b_5, b_6\}$\\
	4 & a := a + 1 & $\{a_4, b_5, b_6\}$ & $\{a_3, a_4, a_5, a_6, b_5, b_6\}$\\
	5 & c := a + b & $\{a_3, a_4, a_5, a_6, b_5, b_6\}$ & $\{a_3, a_4, a_6, b_5, b_6, c_6\}$\\
	- & done & - & -\\
	6 & d := a * b * c & $\{a_6, b_6, c_6\}$ & $\emptyset$\\
	\hline
	\end{tabular}
\end{center}
Réduisons désormais le bloc d'étiquette 5 et appliquons le filtre $I_{\{5\}}[\mu_P]$ sur l'analyse,
\begin{center}
	\begin{tabular}{||c|l|r|l||}
	\hline
	Étiq. & Bloc & $\livein{\cdot}$ & $\liveout{\cdot}$ \\
	\hline
	1 & a := 1 & $\emptyset$ & $\{a_2, a_3, a_4\}$\\
	2 & b := a & $\{a_2, a_3, a_4\}$ & $\{a_3, a_4, b_6\}$\\
	3 & while a < 100 do & $\{a_3, a_4, b_6\}$ & $\{a_4, b_6\}$\\
	4 & a := a + 1 & $\{a_4, b_6\}$ & $\{a_3, a_4, a_6, b_6\}$\\
	5 & () & $\{a_3, a_4, a_6, b_6\}$ & $\{a_3, a_4, a_6, b_6, c_6\}$\\
	- & done & - & -\\
	6 & d := a * b * c & $\{a_6, b_6, c_6\}$ & $\emptyset$\\
	\hline
	\end{tabular}
\end{center}
On a bien obtenu un pré-point fixe de cette déclaration réduite à partir de l'analyse de vivacité précédente.
Par la monotonie de l'algorithme d'itération, on peut donc faire croître ce treillis et trouver le point fixe minimal. 
\section{Généralisation}
Ceci achève une première analyse statique qu'est l'analyse de vivacité. On s'essaye maintenant à déterminer
un lien plus général entre le prédicat, le treillis, et la transformation de code.
\subsection{Motivations}
On cherche à implémenter un meta-langage, qui servira entre notre langage et son compilateur, à orienter
ce dernier sur les optimisations à fournir. Pour ce faire, on se sert de prédicats qui valideront ou non la
transformation du code et cette dernière sera plus ou moins efficace selon le treillis qu'on décidera d'utiliser. 
Ces prédicats sont des applications prenant des éléments évaluables à la compilation, 
dans notre cas, des variables et plus tard, des routines.
Soit $P : \mathbb{V} \longrightarrow \{0, 1\}$ un prédicat quelconque, voici un exemple d'un tel programme,
\begin{lstlisting}[tabsize=2]
	...
	x := a;
	...
	y := 0;
	#if P(x)
		while(y < x) do
			y := y + 1
		done;
	#else
		y := 1;
	#endif
	...
\end{lstlisting}
La bonne utilisation de ces prédicats doit permettre la production d'un code assembleur minimal et le plus
optimal possible, ce qui s'avère essentiel lorsqu'on recherche de hautes performances d'exécution.
Revenons-en à un langage impératif tel que C pour illustrer cela. Supposons qu'on ait une simple fonction de division 
par 32 d'un entier sur 32 bits.
\begin{lstlisting}[tabsize=2, language=c]
	int div(int x)
	{
		return x/32;
	}
\end{lstlisting}
Le compilateur GCC produit alors le code assembleur suivant,
\begin{lstlisting}[tabsize=2]
	div:
		mov     eax, DWORD PTR [rbp-4]
		lea     edx, [rax+31]
		test    eax, eax
		cmovs   eax, edx
		sar     eax, 5
		ret
\end{lstlisting}
On suppose désormais que cette fonction sera appelée dans une boucle, à ne traiter que des entiers signés sur 32 bits, positifs.
Alors ce code assembleur devient particulièrement inefficace étant donné qu'il considère le cas d'entiers
négatifs. En effet, on aimerait plutôt avoir quelque chose comme,
\begin{lstlisting}[tabsize=2]
	div:
		mov     eax, DWORD PTR [rbp-4]
		shr     eax, 5
		ret
\end{lstlisting}
ce qui est déjà bien mieux! On pourrait donc dans ce cas poser notre meta-langage sur l'appel de \textit{div}, avec un prédicat
défini par,
\[P : v \longmapsto \intrfun{v > 0 \vee v = 0}{B}(\sigma)\]
où $\sigma$ est l'état de nos variables sur la pile. Cela donnerait l'hypothèse d'un entier positif à la pré-compilation
et permettrait d'obtenir ce code assembleur spécifiquement.
\subsection{Première approche}
Entamons cette généralisation en partant d'équations similaires à celles de l'analyse de vivacité.
On remarque en effet que pour toute sorte d'analyses statiques, on retrouvera toujours l'opérateur $\sqcup$
sur les blocs successeurs ou prédecesseurs. Définissons donc une fonction de transfert $t_l$ au bloc d'étiquette $l$
telle que,
\[
	t_l : L \longrightarrow L	
\]
où $(L, \sqsubseteq)$ est un treillis quelconque. Par exemple, la fonction de transfert pour l'analyse de vivacité est définie par,
\[
	t_l(s) = \sgen{l} \cup (s - \skill{l})	
\] 
On se donne alors pour commencer, les équations,
\begin{align*}
	A_{in}[l] &= t_l(A_{out}[l])\\
	A_{out}[l]&= \bigsqcup\limits_{p \in \mathcal{K}_l} A_{in}[p]
\end{align*}
L'analyse de vivacité développée plus haut se faisait de bas en haut dans le parcours du CFG, on avait alors
\[\mathcal{K}_l = succ(l)\] 
Cependant, si l'analyse se fait de haut en bas, on aurait alors plutôt
\[\mathcal{K}_l = pred(l)\]
Jusqu'à maintenant, nous avions utilisé l'union des blocs dans le cadre de l'analyse de vivacité. Cela nous fournissait
une analyse dans laquelle les informations requises étaient possiblement vraies. On peut néanmoins restreindre encore plus
nos analyses en prenant $\sqcup=\cap$. Dans ce cas, l'information requise doit tout le temps être vraie. On notera que cette
restriction supplémentaire change l'ordre dans notre treillis, avec $\sqsubseteq=\supseteq$.
\\
Ainsi on peut chercher des contraintes à poser sur les prédicats, en fonction de ces deux dimensions que sont l'analyse par
l'avant, par l'arrière, intersectée ou à l'union.
\section{Annexe}
\subsection{Validation}
\subsection{Tests unitaires}
\subsection{Générateur}
Dans l'optique de vérification de la robustesse de nos différentes analyses, il peut être bon de réaliser
des tests unitaires sur chacune d'elles. Pour cela on ne se restreindra pas aux tests conçus pas nous-même
mais on essayera aussi de trouver tous les cas de figure par la manière forte. Un générateur de code complètement
arbitraire est alors une bonne solution pour réaliser de tels tests.
\\
Ce générateur de code est ajusté par un paramètre qu'est la quantité de variables affectées dans la déclaration. On
cherche également à ce que le code généré soit le plus proche possible de celui qu'aurait pu fournir un humain.
Dans notre syntaxe, il suffit pour le moment de donner une certaine répartition lors de la création des déclarations,
en permettant plus d'affectations, que des blocs Ifte ou Whiledo par exemple.
\subsection{Bugs}
\section{Conclusion}
\end{document}